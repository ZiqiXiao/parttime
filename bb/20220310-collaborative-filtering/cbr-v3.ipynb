{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# mixed recommendation: user based collaborative filtering and content based recommendation\n",
    "class UBFCBR:\n",
    "    def __init__(self, filepath, k=10, n=10):\n",
    "        self.filepath = filepath\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "\n",
    "        self.train, self.test = self.load_data()\n",
    "\n",
    "        self.train_data, self.test_data = self.split_data()\n",
    "        self.user_sim_matrix = self.user_similarity()\n",
    "        self.cbr_user_item_sim = self.cbr_user_item_sim()\n",
    "\n",
    "        self.recommendation = self.recommend()\n",
    "\n",
    "\n",
    "    # load data\n",
    "    def load_data(self):\n",
    "        print(\"加载数据...\")\n",
    "        rating = pd.read_csv(self.filepath)\n",
    "        train, test = train_test_split(rating, test_size=0.2, random_state=42)\n",
    "        train_dict = train.iloc[:,:3].to_dict('split')\n",
    "        train_dict = train_dict['data']\n",
    "\n",
    "\n",
    "        return train, test\n",
    "\n",
    "    # split data\n",
    "    def split_data(self):\n",
    "        print(\"分割数据...\")\n",
    "        train = self.train.iloc[:,:3].to_dict('split')\n",
    "        train  = train['data']\n",
    "\n",
    "        test = self.test.iloc[:,:3].to_dict('split')\n",
    "        test  = test['data']\n",
    "\n",
    "        train_data = {}\n",
    "        test_data = {}\n",
    "        # control the random seed\n",
    "        np.random.seed(1)\n",
    "        for user, item, rating in train:\n",
    "            if user not in train_data:\n",
    "                train_data[user] = {}\n",
    "            train_data[user][item] = rating\n",
    "        for user, item, rating in test:\n",
    "            if user not in test_data:\n",
    "                test_data[user] = {}\n",
    "            test_data[user][item] = rating\n",
    "        return train_data, test_data\n",
    "\n",
    "    # calculate the similarity between users with cosine similarity using train data\n",
    "    def user_similarity(self):\n",
    "        print(\"计算用户相似度矩阵...\")\n",
    "        # build the inverse table for item_users\n",
    "        item_users = dict()\n",
    "        for user, items in self.train_data.items():\n",
    "            for item in items.keys():\n",
    "                if item not in item_users:\n",
    "                    item_users[item] = set()\n",
    "                item_users[item].add(user)\n",
    "        # calculate co-rated items between users\n",
    "        C = dict()\n",
    "        N = dict()\n",
    "        for item, users in item_users.items():\n",
    "            for u in users:\n",
    "                if u not in N:\n",
    "                    N[u] = 0\n",
    "                N[u] += 1\n",
    "                for v in users:\n",
    "                    if u == v:\n",
    "                        continue\n",
    "                    if u not in C:\n",
    "                        C[u] = {}\n",
    "                    if v not in C[u]:\n",
    "                        C[u][v] = 0\n",
    "                    C[u][v] += 1\n",
    "        # calculate finial similarity matrix W\n",
    "        W = dict()\n",
    "        for u, related_users in C.items():\n",
    "            if u not in W:\n",
    "                W[u] = {}\n",
    "            for v, cuv in related_users.items():\n",
    "                W[u][v] = cuv / np.sqrt(N[u] * N[v])\n",
    "        return W\n",
    "\n",
    "    def cbr_user_item_sim(self):\n",
    "        movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "        ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "\n",
    "        # split ratings into train and test\n",
    "        train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "        # transfer movies genre to 0-1 matrix based on genre\n",
    "        movies['genres'] = movies['genres'].str.split('|')\n",
    "        movies = movies.join(movies.genres.str.join('|').str.get_dummies())\n",
    "\n",
    "        # lookup users watched movie and their genre, then sum up\n",
    "        user_genre = train_data.groupby('userId').apply(lambda x: x.merge(movies, on='movieId', how='left').iloc[:, 3:].sum())\n",
    "\n",
    "        df = ratings.merge(movies, on='movieId', how='left')\n",
    "        for i in range(len(df)):\n",
    "            df.iloc[i, 6:] = df.iloc[i, 6:] * df.iloc[i, 2]\n",
    "\n",
    "        df_sum = df.groupby('userId').apply(lambda x: x.iloc[:, 6:].sum())\n",
    "        user_avg = ratings.groupby('userId')['rating'].mean()\n",
    "\n",
    "        user_pref = df_sum.copy()\n",
    "        for i in range(len(user_pref)):\n",
    "            user_pref.iloc[i, :] = (df_sum.iloc[i, :] - (user_avg[i+1] * user_genre.iloc[i, 3:])) / user_genre.iloc[i, 3:]\n",
    "        user_pref = user_pref.fillna(0)\n",
    "        user_pref = user_pref.replace(np.inf, 0)\n",
    "\n",
    "        # calculate cosine similarity between users and movies based on 1-0 matrix\n",
    "        user_item_sim = cosine_similarity(user_pref, movies.iloc[:, 3:])\n",
    "\n",
    "        # transfer train data to dictionary\n",
    "        train_data = train_data.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "        # look up user's top 10 similar movies and return in a dictionary\n",
    "        user_item_sim = pd.DataFrame(user_item_sim, index=user_genre.index, columns=movies['movieId'])\n",
    "\n",
    "        # normalization of user_item_sim\n",
    "        user_item_sim = user_item_sim.apply(lambda x: ((x - np.min(x)) / (np.max(x) - np.min(x)) * 5), axis=1)\n",
    "\n",
    "        # transfer user_item_sim to dictionary\n",
    "        user_item_sim = user_item_sim.to_dict('index')\n",
    "\n",
    "        return user_item_sim\n",
    "\n",
    "    # recommend items for each user\n",
    "    def recommend(self, wht=0.8):\n",
    "        print(\"为每个用户推荐物品...\")\n",
    "        rank = dict()\n",
    "        cbr_recommend = dict()\n",
    "        recommendation = dict()\n",
    "        for user in self.train_data.keys():\n",
    "            rank[user] = dict()\n",
    "            interacted_items = self.train_data[user]\n",
    "            for v, wuv in sorted(self.user_sim_matrix[user].items(), key=lambda x: x[1], reverse=True)[0:self.k]:\n",
    "                for i, rvi in self.train_data[v].items():\n",
    "                    if i in interacted_items:\n",
    "                        continue\n",
    "                    if i not in rank[user]:\n",
    "                        rank[user][i] = 0\n",
    "                    rank[user][i] += wuv * rvi\n",
    "            max_score = max(rank[user].values())\n",
    "            min_score = min(rank[user].values())\n",
    "            for i in rank[user].keys():\n",
    "                rank[user][i] = ((rank[user][i] - min_score) / (max_score - min_score)) * 5\n",
    "\n",
    "            cbr_recommend[user] = dict()\n",
    "            for v, j in self.cbr_user_item_sim[user].items():\n",
    "                if v not in interacted_items:\n",
    "                    cbr_recommend[user][v] = j\n",
    "\n",
    "        for u, i in cbr_recommend.items():\n",
    "            recommendation[u] = dict()\n",
    "            for v, j in cbr_recommend[u].items():\n",
    "                try:\n",
    "                    recommendation[u][v] = rank[u][v] * wht + j * (1 - wht)\n",
    "                except:\n",
    "                    recommendation[u][v] = j\n",
    "        return recommendation\n",
    "\n",
    "    # calculate the precision, recall, mae\n",
    "    def evaluate(self, nitems):\n",
    "        print(\"评估模型...\")\n",
    "        hit = 0\n",
    "        mae = 0\n",
    "        n_recall = 0\n",
    "        n_precision = 0\n",
    "        n_mae = 0\n",
    "        for user in self.train_data.keys():\n",
    "            test_items = self.test_data.get(user, {})\n",
    "            rank = self.recommendation[user]\n",
    "            for item, w in sorted(rank.items(), key=lambda x: x[1], reverse=True)[0:nitems]:\n",
    "                if item in test_items:\n",
    "                    hit += 1\n",
    "                    mae += abs(w - test_items[item])\n",
    "                    n_mae += 1\n",
    "            n_recall += len(test_items)\n",
    "            n_precision += nitems\n",
    "        return hit / (1.0 * n_precision), hit / (1.0 * n_recall), mae / (1.0 * n_mae)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据...\n",
      "分割数据...\n",
      "计算用户相似度矩阵...\n",
      "为每个用户推荐物品...\n"
     ]
    }
   ],
   "source": [
    "ubfcbr = UBFCBR('ml-latest-small/ratings.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估模型...\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.03360655737704918, 0.010164617215390718, 0.7121503132430916)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubfcbr.evaluate(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = [5, 10, 15, 20, 25, 30]\n",
    "precision_ubfcbr = []\n",
    "recall_ubfcbr = []\n",
    "mae_ubfcbr = []\n",
    "precision_ubf = []\n",
    "recall_ubf = []\n",
    "mae_ubf = []\n",
    "# precision_uibf = []\n",
    "# recall_uibf = []\n",
    "# mae_uibf = []\n",
    "\n",
    "for i in n:\n",
    "    precision, recall, mae = ubfcbr.evaluate(i)\n",
    "    precision_ibf.append(precision)\n",
    "    recall_ibf.append(recall)\n",
    "    mae_ibf.append(mae)\n",
    "\n",
    "    precision, recall, mae = ubf.evaluate(i)\n",
    "    precision_ubf.append(precision)\n",
    "    recall_ubf.append(recall)\n",
    "    mae_ubf.append(mae)\n",
    "\n",
    "    # precision, recall, mae = uibf.evaluate(i)\n",
    "    # precision_uibf.append(precision)\n",
    "    # recall_uibf.append(recall)\n",
    "    # mae_uibf.append(mae)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
